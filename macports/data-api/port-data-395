{"count": 29693, "next": "http://ports.macports.org/api/v1/ports/?format=json&page=396", "previous": "http://ports.macports.org/api/v1/ports/?format=json&page=394", "results": [{"name": "retail", "portdir": "textproc/retail", "version": "1.0.2", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://xjack.org/retail/", "description": "Re-Tail is a command line program which is intended as an intelligent incremental logfile reader.", "long_description": "Re-Tail is a command line program which is intended as an intelligent incremental logfile reader. It will read a file or group of files given on the command line, and output any changes since last time it read the file(s) in question. It will attempt to compensate if the filesize changes unexpectedly, and will also attempt to compensate if the file contents changes as well. It is not a very complex program.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "mps", "github": "Schamschula", "ports_count": 394}], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "rfcdiff", "portdir": "textproc/rfcdiff", "version": "1.34", "license": "unknown", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://tools.ietf.org/tools/rfcdiff/", "description": "compare Internet Draft versions", "long_description": "The purpose of this program is to compare two versions of an Internet Draft and produce a diff.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "ripgrep", "portdir": "textproc/ripgrep", "version": "13.0.0", "license": "MIT", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://github.com/BurntSushi/ripgrep", "description": "fast command line search tool", "long_description": "ripgrep is a command line search tool that combines the usability of The Silver Searcher (an ack clone) with the raw speed of GNU grep.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "raimue", "github": "raimue", "ports_count": 93}], "variants": ["pcre", "universal"], "dependencies": [{"type": "build", "ports": ["cargo", "asciidoc", "docbook-xsl-nons", "clang-12"]}], "depends_on": [{"type": "run", "ports": ["ripgrep-all"]}]}, {"name": "rfksay", "portdir": "textproc/rfksay", "version": "0.1", "license": "unknown", "platforms": "darwin freebsd", "epoch": 0, "replaced_by": null, "homepage": "http://freebsdcluster.org/~mich/software/", "description": "Generates a kitten finding robot with a text bubble", "long_description": "Generates a kitten finding robot with a text bubble", "active": true, "categories": ["textproc", "amusements"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "rhyme", "portdir": "textproc/rhyme", "version": "0.9", "license": "GPL-2", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://rhyme.sourceforge.net/", "description": "Rhyming dictionary", "long_description": "Command-line program that takes a word and returns to you a formatted list of all words that rhyme with it.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "macports", "github": "Raimondi", "ports_count": 6}], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "lib", "ports": ["gdbm", "ncurses", "readline"]}], "depends_on": []}, {"name": "ripgrep-all", "portdir": "textproc/ripgrep-all", "version": "0.9.6", "license": "AGPL", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://github.com/phiresky/ripgrep-all", "description": "rga: ripgrep, but also search in PDFs, E-Books, Office documents, zip, tar.gz, etc.", "long_description": "rga is a line-oriented search tool that allows you to look for a regex in a multitude of file types. rga wraps the awesome ripgrep and enables it to search in pdf, docx, sqlite, jpg, movie subtitles (mkv, mp4), etc.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "herby.gillot", "github": "herbygillot", "ports_count": 445}], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["cargo", "clang-9.0"]}, {"type": "run", "ports": ["ripgrep"]}], "depends_on": []}, {"name": "rman", "portdir": "textproc/rman", "version": "3.2", "license": "Artistic-1", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://polyglotman.sourceforge.net/", "description": "Man page format converter", "long_description": "PolyglotMan takes formatted man pages from most of the popular flavours of UN*X and transforms them into any number of source formats. It can produce ASCII-only, section headers-only, TkMan, [tn]roff, Ensemble, SGML, HTML, LaTeX, RTF, Perl 5 POD.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": [{"type": "build", "ports": ["spim"]}]}, {"name": "rnnlm", "portdir": "textproc/rnnlm", "version": "0.4b", "license": "Permissive", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://rnnlm.org", "description": "Recurrent Neural Network Language Modeling Toolkit", "long_description": "Neural network based language models are nowdays among the most successful techniques for statistical language modeling. They can be easily applied in wide range of tasks, including automatic speech recognition and machine translation, and provide significant improvements over classic backoff n-gram models.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "seekanser", "portdir": "textproc/seekanser", "version": "1.0.7", "license": "LGPL-3", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://seekanser.sourceforge.jp/", "description": "a program to seek answers to a quiz in Japanese", "long_description": "SeekAnser is a program to seek answers to a quiz in Japanese.", "active": true, "categories": ["textproc", "java", "japanese"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["chasen"]}], "depends_on": []}, {"name": "rpl", "portdir": "textproc/rpl", "version": "1.4.1", "license": "Restrictive/Distributable", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.laffeycomputer.com/rpl.html", "description": "Rpl is a Unix replacement utility", "long_description": "rpl is a Unix text replacement utility. It will replace strings with new strings in multiple text files. It can scan directories recursively and replace strings in all files found. The search can be limited to files with certain filename suffixes (e.g. '.html', '.c', etc.).", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "rst2pdf", "portdir": "textproc/rst2pdf", "version": "0.93", "license": "MIT", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://code.google.com/p/rst2pdf/", "description": "Create PDF from reStructuredText", "long_description": "Create PDF from reStructuredText", "active": true, "categories": ["textproc", "python"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "lib", "ports": ["py27-docutils", "py27-pdfrw", "python27", "py27-setuptools", "py27-reportlab"]}, {"type": "run", "ports": ["py27-pygments"]}], "depends_on": []}, {"name": "scdoc", "portdir": "textproc/scdoc", "version": "1.11.1", "license": "MIT", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://git.sr.ht/~sircmpwn/scdoc", "description": "Simple man page generator.", "long_description": "scdoc is a simple man page generator for POSIX systems written in C99.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": [{"type": "build", "ports": ["astroid", "aerc", "kiln", "ijq", "nvimpager", "shfmt"]}]}, {"name": "sword-bible-darby", "portdir": "textproc/sword-bible-darby", "version": "1.1", "license": "public-domain", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.crosswire.org/sword/modules/ModInfo.jsp?modName=Darby", "description": "Darby Bible (1889)", "long_description": "A literal translation of the Old Testament (1890) and the New Testament (1884) By John Nelson Darby (1800-82)", "active": true, "categories": ["textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["sword"]}], "depends_on": []}, {"name": "recoll", "portdir": "textproc/recoll", "version": "1.31.2", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://www.lesbonscomptes.com/recoll/", "description": "Desktop full text search", "long_description": "Recoll is a desktop search tool based on Xapian", "active": true, "categories": ["textproc"], "maintainers": [{"name": "jf", "github": "medoc92", "ports_count": 1}], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0", "pkgconfig"]}, {"type": "lib", "ports": ["zlib", "xapian-core", "aspell", "libiconv", "qt5-qtbase", "qt5-qtwebkit"]}, {"type": "run", "ports": ["python37", "py37-lxml", "antiword", "unrtf", "poppler", "unzip"]}], "depends_on": []}, {"name": "rtfreader", "portdir": "textproc/rtfreader", "version": "1.0", "license": "unknown", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.fiction.net/blong/programs/#rtf", "description": "Utility to read Microsoft RTF files", "long_description": "RTF is the Microsoft Rich Text Format, a more portable, mostly ASCII formatting language that is exported by word processors like MS Word. The files generally have the extension .rtf, but occasionally have .doc extensions as well. This parser is from the Microsoft spec, ported to Unix systems.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "rxp", "portdir": "textproc/rxp", "version": "1.4.8", "license": "unknown", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.cogsci.ed.ac.uk/~richard/rxp.html", "description": "Validating XML parser written in C.", "long_description": "RXP is a validating XML parser written in C. The current version of RXP supports XML 1.1, Namespaces 1.1, xml:id, and XML Catalogs.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "sablotron", "portdir": "textproc/sablotron", "version": "1.0.3", "license": "(MPL-1.1 or GPL-2+)", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://sablotron.sourceforge.net/", "description": "XSLT, DOM and XPath processor", "long_description": "Sablotron is a fast, compact and portable XML toolkit implementing XSLT 1.0, DOM Level2 and XPath 1.0. Sablotron is an open project. The goal of this project is to create a lightweight, reliable and fast XML library processor conforming to the W3C specification, which is available for public and can be used as a base for multi-platform XML applications.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["apidocs", "debugger", "universal"], "dependencies": [{"type": "build", "ports": ["libtool", "clang-9.0"]}, {"type": "lib", "ports": ["spidermonkey", "expat", "libiconv"]}], "depends_on": [{"type": "lib", "ports": ["arb"]}]}, {"name": "sand", "portdir": "textproc/sand", "version": "0.3.0-20021016", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://sand.sourceforge.net/", "description": "sand is a tool to help you keep your diary", "long_description": "sand is a tool to help you keep your diary", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["autoconf", "automake", "libtool", "clang-9.0", "texinfo"]}], "depends_on": []}, {"name": "saxon", "portdir": "textproc/saxon", "version": "9.5.1.1", "license": "MPL-1", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://saxon.sourceforge.net/", "description": "saxon home edition - collection of tools to process XML documents", "long_description": "Saxon-HE provides implementations of XSLT 2.0, XQuery 1.0, and XPath 2.0 at the basic level of conformance defined by W3C.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["kaffe"]}], "depends_on": []}, {"name": "sd", "portdir": "textproc/sd", "version": "0.7.6", "license": "MIT", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://github.com/chmln/sd", "description": "Intuitive find & replace CLI (sed alternative)", "long_description": "Intuitive find & replace CLI (sed alternative). sd uses regex syntax that you already know from JavaScript and Python. Forget about dealing with quirks of sed or awk - get productive immediately.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "herby.gillot", "github": "herbygillot", "ports_count": 445}], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["cargo", "clang-9.0"]}], "depends_on": []}, {"name": "sdcv", "portdir": "textproc/sdcv", "version": "0.5.3", "license": "GPL-2+", "platforms": "darwin", "epoch": 1, "replaced_by": null, "homepage": "https://dushistov.github.io/sdcv/", "description": "console version of StarDict program", "long_description": "sdcv is a console version of the StarDict program.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "ryandesign", "github": "ryandesign", "ports_count": 1396}], "variants": ["debug", "universal"], "dependencies": [{"type": "build", "ports": ["cmake", "pkgconfig", "clang-9.0"]}, {"type": "lib", "ports": ["zlib", "readline", "gettext", "glib2"]}], "depends_on": []}, {"name": "senna", "portdir": "textproc/senna", "version": "1.1.4", "license": "unknown", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://qwik.jp/senna/", "description": "embeddable fulltext search engine", "long_description": "Senna is an embeddable fulltext search engine, which you can use in conjunction with various scripting languages and databases.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "hello", "github": "", "ports_count": 1}], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "lib", "ports": ["mecab", "mecab-ipadic-utf8"]}], "depends_on": []}, {"name": "sentencepiece", "portdir": "textproc/sentencepiece", "version": "0.1.95", "license": "Apache-2", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://github.com/google/sentencepiece", "description": "Unsupervised text tokenizer for Neural Network-based text generation.", "long_description": "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements subword units (e.g., byte-pair-encoding (BPE) [Sennrich et al.]) and unigram language model [Kudo.]) with the extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["debug", "universal"], "dependencies": [{"type": "build", "ports": ["cmake", "clang-9.0"]}, {"type": "lib", "ports": ["gperftools"]}], "depends_on": [{"type": "lib", "ports": ["py37-sentencepiece", "py38-sentencepiece", "py39-sentencepiece"]}]}, {"name": "sgml-common", "portdir": "textproc/sgml-common", "version": "0.6.3", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.w3.org/2003/entities/", "description": "A collection of entities and DTDs common to multiple packages.", "long_description": "The sgml-common package contains a collection of entities and DTDs that are useful for processing SGML, but that don't need to be included in multiple packages. Sgml-common also includes an up-to-date Open Catalog file. Transcribed from the Fedora 15 RPM written originally by Tim Waugh <twaugh@redhat.com> based on work by Eric Bischoff and with recent maintenance by Ondrej Vasik <ovasik@redhat.com>.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "tlockhart1976", "github": "lockhart", "ports_count": 25}], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "lib", "ports": ["perl5", "libxml2", "xmlcatmgr"]}], "depends_on": [{"type": "lib", "ports": ["docbook-utils"]}]}, {"name": "sgrep", "portdir": "textproc/sgrep", "version": "0.99", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.cs.helsinki.fi/u/jjaakkol/sgrep.html", "description": "structured grep is a tool for searching SGML, XML and HTML files", "long_description": "sgrep (structured grep) is a tool for searching and indexing text, SGML, XML and HTML files and filtering text streams using structural criteria.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "sgrep2", "portdir": "textproc/sgrep2", "version": "1.94a", "license": "unknown", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://www.cs.helsinki.fi/u/jjaakkol/sgrep.html", "description": "structured grep is a tool for searching SGML, XML and HTML files", "long_description": "sgrep (structured grep) is a tool for searching and indexing text, SGML, XML and HTML files and filtering text streams using structural criteria.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "simstring", "portdir": "textproc/simstring", "version": "20140723", "license": "BSD", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.chokkan.org/software/simstring/", "description": "A fast and simple algorithm for approximate string matching/retrieval", "long_description": "SimString is a simple library for fast approximate string retrieval. Approximate string retrieval finds strings in a database whose similarity with a query string is no smaller than a threshold. Finding not only identical but similar strings, approximate string retrieval has various applications including spelling correction, flexible dictionary matching, duplicate detection, and record linkage.", "active": true, "categories": ["textproc", "math"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["autoconf", "automake", "libtool", "clang-9.0"]}], "depends_on": []}, {"name": "source-highlight", "portdir": "textproc/source-highlight", "version": "3.1.9", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://www.gnu.org/software/src-highlite/", "description": "source-code syntax highlighter", "long_description": "This program, given a source file, produces a document with syntax highlighting. At the moment it can handle: C/C++, C#, Bib, Bison, Caml, Changelog, CSS, Diff, Flex, Fortran, Html, Java, Javascript, Latex, Logtalk, Log files, Lua, Makefile, M4, ML, Pascal, Perl, PHP, PostScript, Prolog, Python, Ruby, Shell, Sql, Tcl, and XML.", "active": true, "categories": ["devel", "textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["autoconf", "automake", "libtool", "clang-9.0"]}, {"type": "lib", "ports": ["ctags", "boost171"]}], "depends_on": []}, {"name": "py27-simstring", "portdir": "textproc/simstring", "version": "20140723", "license": "BSD", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.chokkan.org/software/simstring/", "description": "SimString Python module", "long_description": "SimString Python module", "active": true, "categories": ["textproc", "math", "python"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["autoconf", "automake", "libtool", "swig-python", "clang-9.0"]}, {"type": "lib", "ports": ["python27"]}], "depends_on": []}, {"name": "slearp", "portdir": "textproc/slearp", "version": "0.95", "license": "GPL-3", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://sourceforge.jp/projects/slearp/", "description": "structured learning and predict toolkit for tasks such as g2p conversion, based on discriminative leaning", "long_description": "Slearp (structured learning and prediction) is the structured learning and predict toolkit for tasks such as g2p conversion, based on discriminative leaning.", "active": true, "categories": ["textproc", "math"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "sloccount", "portdir": "textproc/sloccount", "version": "2.26", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://dwheeler.com/sloccount/", "description": "program for counting lines of code in a large number of languages", "long_description": "SLOCCount is a set of tools for counting physical Source Lines of Code (SLOC) in a large number of languages of a potentially large set of programs.", "active": true, "categories": ["devel", "textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "run", "ports": ["perl5", "bash"]}], "depends_on": []}, {"name": "sowing", "portdir": "textproc/sowing", "version": "1.1.25", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://mcs.anl.gov", "description": "A parser for fortran interfaces", "long_description": "A parser for fortran interfaces", "active": true, "categories": ["textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": [{"type": "build", "ports": ["petsc", "slepc"]}]}, {"name": "spark", "portdir": "textproc/spark", "version": "1.0.1", "license": "MIT", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://github.com/holman/spark", "description": "sparklines for your shell.", "long_description": "spark: sparklines for your shell.", "active": true, "categories": ["textproc"], "maintainers": [{"name": "g5pw", "github": "g5pw", "ports_count": 122}], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "webredirect", "portdir": "www/webredirect", "version": "0.3", "license": "Permissive", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://rasmus.krats.se/2001/webredirect.en", "description": "small webserver which redirects all requests", "long_description": "webredirect is a small web server serving 301 Moved Permanently or 302 Moved Temporarily to all requests.", "active": true, "categories": ["www"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "sphinx", "portdir": "textproc/sphinx", "version": "2.2.11", "license": "GPL-2", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://sphinxsearch.com/", "description": "Sphinx is a full-text search engine", "long_description": "Sphinx is a full-text search engine, meant to provide fast, size-efficient and relevant fulltext search functions to other applications. Sphinx was specially designed to integrate well with SQL databases and scripting languages. Currently built-in data sources support fetching data either via direct connection to MySQL or PostgreSQL, or from an XML pipe.", "active": true, "categories": ["net", "textproc"], "maintainers": [], "variants": ["postgresql91", "postgresql92", "postgresql93", "postgresql94", "postgresql95", "postgresql96", "mysql51", "mysql55", "mysql56", "mysql57", "mariadb", "percona", "universal"], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "lib", "ports": ["mysql57", "expat", "libiconv"]}], "depends_on": []}, {"name": "libsphinxclient", "portdir": "textproc/sphinx", "version": "2.2.11", "license": "LGPL-2", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://sphinxsearch.com/", "description": "C library to talk to the Sphinx full-text search engine", "long_description": "C library to talk to the Sphinx full-text search engine", "active": true, "categories": ["net", "textproc"], "maintainers": [], "variants": ["universal"], "dependencies": [{"type": "build", "ports": ["autoconf", "automake", "libtool", "clang-9.0"]}], "depends_on": [{"type": "lib", "ports": ["php53-sphinx", "php54-sphinx", "php55-sphinx", "php56-sphinx"]}]}, {"name": "stanford-corenlp", "portdir": "textproc/stanford-corenlp", "version": "3.9.2", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://stanfordnlp.github.io/CoreNLP/", "description": "A Java suite of core NLP tools", "long_description": "Stanford CoreNLP provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities. It was originally developed for English, but now also provides varying levels of support for (Modern Standard) Arabic, (mainland) Chinese, French, German, and Spanish. Stanford CoreNLP is an integrated framework, which makes it very easy to apply a bunch of language analysis tools to a piece of text. Starting from plain text, you can run all the tools with just two lines of code. Its analyses provide the foundational building blocks for higher-level and domain-specific text understanding applications. Stanford CoreNLP is a set of stable and well-tested natural language processing tools, widely used by various groups in academia, industry, and government. The tools variously use rule-based, probabilistic machine learning, and deep learning components.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["apache-ant", "openjdk11"]}, {"type": "run", "ports": ["stanford-corenlp-models"]}], "depends_on": [{"type": "run", "ports": ["py27-stanfordnlp", "py37-stanfordnlp", "py38-stanfordnlp", "stanford-corenlp-arabic", "stanford-corenlp-chinese", "stanford-corenlp-english", "stanford-corenlp-english-kbp", "stanford-corenlp-french", "stanford-corenlp-german", "stanford-corenlp-spanish"]}]}, {"name": "stanford-corenlp-models", "portdir": "textproc/stanford-corenlp", "version": "3.9.2", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://stanfordnlp.github.io/CoreNLP/", "description": "A Java suite of core NLP tools", "long_description": "Stanford CoreNLP provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities. It was originally developed for English, but now also provides varying levels of support for (Modern Standard) Arabic, (mainland) Chinese, French, German, and Spanish. Stanford CoreNLP is an integrated framework, which makes it very easy to apply a bunch of language analysis tools to a piece of text. Starting from plain text, you can run all the tools with just two lines of code. Its analyses provide the foundational building blocks for higher-level and domain-specific text understanding applications. Stanford CoreNLP is a set of stable and well-tested natural language processing tools, widely used by various groups in academia, industry, and government. The tools variously use rule-based, probabilistic machine learning, and deep learning components.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["openjdk11"]}], "depends_on": [{"type": "run", "ports": ["stanford-corenlp", "stanford-corenlp-arabic", "stanford-corenlp-chinese", "stanford-corenlp-english", "stanford-corenlp-english-kbp", "stanford-corenlp-french", "stanford-corenlp-german", "stanford-corenlp-spanish"]}]}, {"name": "stanford-postagger", "portdir": "textproc/stanford-postagger", "version": "3.5.2", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://nlp.stanford.edu/downloads/tagger.shtml", "description": "a Java implementation of the log-linear part-of-speech taggers", "long_description": "a Java implementation of the log-linear part-of-speech taggers", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}], "depends_on": []}, {"name": "stanford-corenlp-arabic", "portdir": "textproc/stanford-corenlp", "version": "3.9.2", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://stanfordnlp.github.io/CoreNLP/", "description": "A Java suite of core NLP tools", "long_description": "Stanford CoreNLP provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities. It was originally developed for English, but now also provides varying levels of support for (Modern Standard) Arabic, (mainland) Chinese, French, German, and Spanish. Stanford CoreNLP is an integrated framework, which makes it very easy to apply a bunch of language analysis tools to a piece of text. Starting from plain text, you can run all the tools with just two lines of code. Its analyses provide the foundational building blocks for higher-level and domain-specific text understanding applications. Stanford CoreNLP is a set of stable and well-tested natural language processing tools, widely used by various groups in academia, industry, and government. The tools variously use rule-based, probabilistic machine learning, and deep learning components.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["openjdk11"]}, {"type": "run", "ports": ["stanford-corenlp", "stanford-corenlp-models"]}], "depends_on": []}, {"name": "stanford-corenlp-chinese", "portdir": "textproc/stanford-corenlp", "version": "3.9.2", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://stanfordnlp.github.io/CoreNLP/", "description": "A Java suite of core NLP tools", "long_description": "Stanford CoreNLP provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities. It was originally developed for English, but now also provides varying levels of support for (Modern Standard) Arabic, (mainland) Chinese, French, German, and Spanish. Stanford CoreNLP is an integrated framework, which makes it very easy to apply a bunch of language analysis tools to a piece of text. Starting from plain text, you can run all the tools with just two lines of code. Its analyses provide the foundational building blocks for higher-level and domain-specific text understanding applications. Stanford CoreNLP is a set of stable and well-tested natural language processing tools, widely used by various groups in academia, industry, and government. The tools variously use rule-based, probabilistic machine learning, and deep learning components.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["openjdk11"]}, {"type": "run", "ports": ["stanford-corenlp", "stanford-corenlp-models"]}], "depends_on": []}, {"name": "sword-bible-asv", "portdir": "textproc/sword-bible-asv", "version": "1.3", "license": "public-domain", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.crosswire.org/sword/modules/ModInfo.jsp?modName=ASV", "description": "American Standard Version (1901), includes footnotes", "long_description": "The American Standard Version of 1901 is an Americanization of the English Revised Bible, which is an update of the KJV to less archaic spelling and greater accuracy of translation. It has been called The Rock of Biblical Honesty. It is the product of the work of over 50 Evangelical Christian scholars.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["sword"]}], "depends_on": []}, {"name": "stanford-corenlp-english-kbp", "portdir": "textproc/stanford-corenlp", "version": "3.9.2", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://stanfordnlp.github.io/CoreNLP/", "description": "A Java suite of core NLP tools", "long_description": "Stanford CoreNLP provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities. It was originally developed for English, but now also provides varying levels of support for (Modern Standard) Arabic, (mainland) Chinese, French, German, and Spanish. Stanford CoreNLP is an integrated framework, which makes it very easy to apply a bunch of language analysis tools to a piece of text. Starting from plain text, you can run all the tools with just two lines of code. Its analyses provide the foundational building blocks for higher-level and domain-specific text understanding applications. Stanford CoreNLP is a set of stable and well-tested natural language processing tools, widely used by various groups in academia, industry, and government. The tools variously use rule-based, probabilistic machine learning, and deep learning components.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["openjdk11"]}, {"type": "run", "ports": ["stanford-corenlp", "stanford-corenlp-models"]}], "depends_on": []}, {"name": "stanford-corenlp-french", "portdir": "textproc/stanford-corenlp", "version": "3.9.2", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://stanfordnlp.github.io/CoreNLP/", "description": "A Java suite of core NLP tools", "long_description": "Stanford CoreNLP provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities. It was originally developed for English, but now also provides varying levels of support for (Modern Standard) Arabic, (mainland) Chinese, French, German, and Spanish. Stanford CoreNLP is an integrated framework, which makes it very easy to apply a bunch of language analysis tools to a piece of text. Starting from plain text, you can run all the tools with just two lines of code. Its analyses provide the foundational building blocks for higher-level and domain-specific text understanding applications. Stanford CoreNLP is a set of stable and well-tested natural language processing tools, widely used by various groups in academia, industry, and government. The tools variously use rule-based, probabilistic machine learning, and deep learning components.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["openjdk11"]}, {"type": "run", "ports": ["stanford-corenlp", "stanford-corenlp-models"]}], "depends_on": []}, {"name": "stardict-xmlittre", "portdir": "textproc/stardict-xmlittre", "version": "2.4.2", "license": "unknown", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://francois.gannaz.free.fr/Littre/accueil.php", "description": "XMLittr\u00e9 dictionary for stardict", "long_description": "XMLittr\u00e9 dictionary for stardict.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}], "depends_on": []}, {"name": "stanford-corenlp-german", "portdir": "textproc/stanford-corenlp", "version": "3.9.2", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://stanfordnlp.github.io/CoreNLP/", "description": "A Java suite of core NLP tools", "long_description": "Stanford CoreNLP provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities. It was originally developed for English, but now also provides varying levels of support for (Modern Standard) Arabic, (mainland) Chinese, French, German, and Spanish. Stanford CoreNLP is an integrated framework, which makes it very easy to apply a bunch of language analysis tools to a piece of text. Starting from plain text, you can run all the tools with just two lines of code. Its analyses provide the foundational building blocks for higher-level and domain-specific text understanding applications. Stanford CoreNLP is a set of stable and well-tested natural language processing tools, widely used by various groups in academia, industry, and government. The tools variously use rule-based, probabilistic machine learning, and deep learning components.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["openjdk11"]}, {"type": "run", "ports": ["stanford-corenlp", "stanford-corenlp-models"]}], "depends_on": []}, {"name": "stanford-corenlp-spanish", "portdir": "textproc/stanford-corenlp", "version": "3.9.2", "license": "GPL-3+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "https://stanfordnlp.github.io/CoreNLP/", "description": "A Java suite of core NLP tools", "long_description": "Stanford CoreNLP provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities. It was originally developed for English, but now also provides varying levels of support for (Modern Standard) Arabic, (mainland) Chinese, French, German, and Spanish. Stanford CoreNLP is an integrated framework, which makes it very easy to apply a bunch of language analysis tools to a piece of text. Starting from plain text, you can run all the tools with just two lines of code. Its analyses provide the foundational building blocks for higher-level and domain-specific text understanding applications. Stanford CoreNLP is a set of stable and well-tested natural language processing tools, widely used by various groups in academia, industry, and government. The tools variously use rule-based, probabilistic machine learning, and deep learning components.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["openjdk11"]}, {"type": "run", "ports": ["stanford-corenlp", "stanford-corenlp-models"]}], "depends_on": []}, {"name": "stanford-ner", "portdir": "textproc/stanford-ner", "version": "3.9.2", "license": "GPL-2+", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://nlp.stanford.edu/software/CRF-NER.shtml", "description": "a high-performance machine learning based named entity recognition system", "long_description": "a high-performance machine learning based named entity recognition system, including facilities to train models from supervised training data and pre-trained models for English.", "active": true, "categories": ["textproc", "java"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}], "depends_on": []}, {"name": "string_replace", "portdir": "textproc/string_replace", "version": "0.1", "license": "GPL-2", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://freecode.com/projects/string_replace", "description": "searches and replaces a text string or regular expression", "long_description": "This tool was designed to go through text files (meaning: text, html, php, etc.) to search for and replace a particular text string (or regular expression).", "active": true, "categories": ["textproc", "perl"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "run", "ports": ["perl5"]}], "depends_on": []}, {"name": "sword-bible-akjv", "portdir": "textproc/sword-bible-akjv", "version": "1.4", "license": "public-domain", "platforms": "darwin", "epoch": 0, "replaced_by": null, "homepage": "http://www.crosswire.org/sword/modules/ModInfo.jsp?modName=AKJV", "description": "American King James Version", "long_description": "This is a new translation of the Bible, based on the original King James Version. It is a simple word for word update from the King James English. It has taken care to change nothing doctrinely, but to simply update the spelling and vocabulary. It has not changed the grammar because that could alter it doctrinely.", "active": true, "categories": ["textproc"], "maintainers": [], "variants": [], "dependencies": [{"type": "build", "ports": ["clang-9.0"]}, {"type": "extract", "ports": ["unzip"]}, {"type": "lib", "ports": ["sword"]}], "depends_on": []}]}